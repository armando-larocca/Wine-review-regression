{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINE QUALITY REGRESSION COMPETITION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armando La Rocca \n",
    "279401\n",
    "s279401@studenti.polito.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is used to clean and tokenize the descriptions \n",
    "\n",
    "class LemmaTokenizer(object): \n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, document): \n",
    "\n",
    "        lemmas = []\n",
    "        for t in word_tokenize(document): \n",
    "            t = t.strip()\n",
    "            t = re.sub('\\W', '', t) #Remove symbols\n",
    "            t = re.sub(r'\\d+', '', t) #Remove numbers\n",
    "            lemma = self.lemmatizer.lemmatize(t)\n",
    "            lemmas.append(lemma) \n",
    "        \n",
    "        return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET PREPARATION AND PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./competition_dataset/dev.tsv\",\"\\t\")\n",
    "\n",
    "# Remove duplicates and transform to lower case\n",
    "df =  df.drop_duplicates()\n",
    "df= df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "\n",
    "# Fill features (region_1,region_2 and descriptions) with missing values\n",
    "df[\"region_2\"] = df[\"region_2\"].fillna(\"other\")\n",
    "df[\"region_1\"] = df[\"region_1\"].fillna(\"other\")\n",
    "df[\"designation\"] = df[\"designation\"].fillna(\"other\")\n",
    "\n",
    "# Drop samples with Nan in other features\n",
    "df = df.dropna()\n",
    "\n",
    "# Mapping same designations in the same way\n",
    "d_tr = df.designation.values\n",
    "\n",
    "new = []\n",
    "for i in range(len(d_tr)):\n",
    "    \n",
    "    if (str(d_tr[i]) == \"riserva\") or (str(d_tr[i]) == \"reserva\") or (str(d_tr[i]) == \"réserve\"):\n",
    "        new.append(\"reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"gran reserva\")  :\n",
    "        new.append(\"grand reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"reserva especial\")  :\n",
    "        new.append(\"special reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"red\") or (str(d_tr[i]) == \"rosso\") or (str(d_tr[i]) == \"tinto\") :\n",
    "        new.append(\"red wine\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"rosé of\") or (str(d_tr[i]) == \"rosado\") or (str(d_tr[i]) == \"rosato\") :\n",
    "        new.append(\"rosé\")\n",
    "        \n",
    "    else: new.append(d_tr[i])\n",
    "        \n",
    "df[\"designation\"] = new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIVIDE DESCRIPTIONS IN 3 CATEGORIES\n",
    "\n",
    "labels = []\n",
    "good_review = []\n",
    "bad_review = []\n",
    "medium_review = []\n",
    "\n",
    "descr = df[\"description\"].values\n",
    "    \n",
    "for i in range(len(descr)):    \n",
    "    x = df.quality.values[i]\n",
    "    if x<=35:\n",
    "        labels.append(0)\n",
    "        bad_review.append(descr[i])\n",
    "    if x>35 and x<65:\n",
    "        labels.append(1)\n",
    "        medium_review.append(descr[i])\n",
    "    if x>=65:\n",
    "        labels.append(2)\n",
    "        good_review.append(descr[i])\n",
    "        \n",
    "labels = np.array(labels)\n",
    "good_review = np.array(good_review)\n",
    "medium_review = np.array(medium_review)\n",
    "bad_review = np.array(bad_review)\n",
    "\n",
    "lemmaTokenizer = LemmaTokenizer()\n",
    "vectorizer = CountVectorizer(tokenizer=lemmaTokenizer,max_df=0.7, min_df=0.05, stop_words=sw.words('english')) \n",
    "vectorizer.fit(good_review)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print(len(vectorizer.stop_words_ ),\"\\n\")\n",
    "good_ = dict(vectorizer.vocabulary_).keys()\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lemmaTokenizer,max_df=0.7, min_df=0.05, stop_words=sw.words('english')) \n",
    "vectorizer.fit(medium_review)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print(len(vectorizer.stop_words_ ),\"\\n\")\n",
    "medium_ = dict(vectorizer.vocabulary_).keys()\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lemmaTokenizer,max_df=0.7, min_df=0.05, stop_words=sw.words('english')) \n",
    "vectorizer.fit(bad_review)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print(len(vectorizer.stop_words_ ),\"\\n\")\n",
    "bad_ = dict(vectorizer.vocabulary_).keys()\n",
    "\n",
    "intersection_set = (set(good_) ^ set(bad_) ^ set(medium_))\n",
    "print(len(intersection_set))\n",
    "\n",
    "list_set = list(intersection_set)\n",
    "dictionary = {}\n",
    "\n",
    "for i in range(len(list_set)) : \n",
    "    key = list_set[i]\n",
    "    dictionary[ key ]  = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.quality\n",
    "df = df.drop(columns=\"quality\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=1)\n",
    "\n",
    "descr_train = X_train.description \n",
    "descr_test = X_test.description \n",
    "\n",
    "X_train = X_train.drop(columns=\"description\")\n",
    "X_test = X_test.drop(columns=\"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train.values)\n",
    "\n",
    "hot_train =  enc.transform(X_train.values)\n",
    "hot_test = enc.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding of description feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmaTokenizer = LemmaTokenizer()\n",
    "\n",
    "# IF APPROACH A1\n",
    "#vectorizer = CountVectorizer() \n",
    "#vectorizer.fit(list_set)\n",
    "\n",
    "# IF APPROACH A2 \n",
    "vectorizer = TfidfVectorizer(tokenizer=lemmaTokenizer, max_df=0.5, min_df=10,stop_words=sw.words('english'), use_idf=False) \n",
    "vectorizer.fit(descr_train)\n",
    "\n",
    "count_train = vectorizer.transform(descr_train)\n",
    "count_test = vectorizer.transform(descr_test)\n",
    "\n",
    "# IF APPROACH A1 OR A2\n",
    "# COMMENT IF APPROACH ND \n",
    "sub_train = hstack([hot_train, count_train])\n",
    "sub_test = hstack([hot_test, count_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    \"n_estimators\" : [200,500],\n",
    "    \"max_depth\" : [2000,None],\n",
    "    \"max_features\": [5,10,\"sqrt\"]\n",
    "}\n",
    "\n",
    "\n",
    "for config in ParameterGrid(params_rf):\n",
    "    regr_ = RandomForestRegressor(**config)\n",
    "    \n",
    "    #IF appraoches A1 or A2\n",
    "    regr_.fit(sub_train, y_train)\n",
    "    \n",
    "    #IF appraoche ND\n",
    "    #regr_.fit(hot_train, y_train)\n",
    "    \n",
    "    y_pred = regr_.predict(sub_test)\n",
    "    \n",
    "    print(config)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    \"hidden_layer_sizes\":[100,500],\n",
    "    \"solver\" : [\"sgd\"],\n",
    "    \"learning_rate\" : [\"adaptive\"],\n",
    "    \"early_stopping\" : [True],\n",
    "    \"learning_rate_init\" : [0.001,0.01],\n",
    "    \"max_iter\" : [200],\n",
    "    \"verbose\" : [True]\n",
    "}\n",
    "\n",
    "for config in ParameterGrid(params_rf):\n",
    "    regr = MLPRegressor( **config)\n",
    "    \n",
    "    #IF appraoches A1 or A2\n",
    "    regr.fit(sub_train, y_train)\n",
    "    \n",
    "    #IF appraoche ND\n",
    "    #regr_.fit(hot_train, y_train)\n",
    "    \n",
    "    y_pred = regr.predict(hot_test)\n",
    "\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EVALUATION PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval preparation with the same preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = pd.read_csv(\"./competition_dataset/eval.tsv\",\"\\t\")\n",
    "\n",
    "eval_ = eval_.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "eval_[\"region_2\"] = eval_[\"region_2\"].fillna(\"other\")\n",
    "eval_[\"region_1\"] = eval_[\"region_1\"].fillna(\"other\")\n",
    "eval_[\"designation\"] = eval_[\"designation\"].fillna(\"other\")\n",
    "\n",
    "d_tr = eval_.designation.values\n",
    "new = []\n",
    "\n",
    "for i in range(len(d_tr)):\n",
    "    \n",
    "    if (str(d_tr[i]) == \"riserva\") or (str(d_tr[i]) == \"reserva\") or (str(d_tr[i]) == \"réserve\"):\n",
    "        new.append(\"reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"gran reserva\")  :\n",
    "        new.append(\"grand reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"reserva especial\")  :\n",
    "        new.append(\"special reserve\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"red\") or (str(d_tr[i]) == \"rosso\") or (str(d_tr[i]) == \"tinto\") :\n",
    "        new.append(\"red wine\")\n",
    "        \n",
    "    elif (str(d_tr[i]) == \"rosé of\") or (str(d_tr[i]) == \"rosado\") or (str(d_tr[i]) == \"rosato\") :\n",
    "        new.append(\"rosé\")\n",
    "        \n",
    "    else: new.append(d_tr[i])\n",
    "        \n",
    "eval_[\"designation\"] = new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr_train = df.description \n",
    "descr_test = eval_.description \n",
    "y = df.quality\n",
    "\n",
    "df = df.drop(columns=\"quality\")\n",
    "X_train = df.drop(columns=\"description\")\n",
    "X_test = eval_.drop(columns=\"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train.values)\n",
    "\n",
    "hot_train =  enc.transform(X_train.values)\n",
    "hot_test = enc.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description encoding  ( in the following sections are reported the best configurations obtained in the validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmaTokenizer = LemmaTokenizer()\n",
    "vectorizer = TfidfVectorizer(tokenizer=lemmaTokenizer,max_df=0.5, min_df=10, stop_words=sw.words('english'),use_idf=False) \n",
    "vectorizer.fit(descr_train)\n",
    "\n",
    "count_train = vectorizer.transform(descr_train)\n",
    "count_test = vectorizer.transform(descr_test)\n",
    "\n",
    "sub_train = hstack([hot_train, count_train])\n",
    "sub_test = hstack([hot_test, count_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model trained on all the development set with the best parameters obtained in the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(learning_rate='adaptive', hidden_layer_sizes=500,\\\n",
    "                     learning_rate_init= 0.01, max_iter= 120, solver= 'sgd', verbose=True,\\\n",
    "                     validation_fraction=0)\n",
    "regr.fit(sub_train, y.values)\n",
    "y_pred = regr.predict(sub_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a csv file\n",
    "consegna = pd.DataFrame({\"Id\": range(0,len(y_pred)) , \"Predicted\": y_pred})\n",
    "consegna.to_csv(\"279401.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
